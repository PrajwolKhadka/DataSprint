{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80c307d8",
   "metadata": {},
   "source": [
    "import data and inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4858f229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e158cb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C:\\Users\\Acer\\Documents\\DataSprint\\data\\DataWaveDataSet.csv\n",
    "file = r\"C:\\Users\\Acer\\Documents\\DataSprint\\data\\DataWaveDataSet.csv\"\n",
    "\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "df.head()\n",
    "df.info()\n",
    "df.shape\n",
    "df.describe()\n",
    "\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bba3bc",
   "metadata": {},
   "source": [
    "Cleaning the user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d3fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_id'].duplicated().sum()\n",
    "\n",
    "df = df.drop_duplicates(subset=['user_id'])\n",
    "\n",
    "df = df.dropna(subset=['user_id'])\n",
    "\n",
    "\n",
    "cleaned_file = r\"C:\\Users\\Acer\\Documents\\DataSprint\\data\\cleaned.csv\"\n",
    "df.to_csv(cleaned_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641f48a8",
   "metadata": {},
   "source": [
    "save the new csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84974552",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_file = r\"C:\\Users\\Acer\\Documents\\DataSprint\\data\\cleaned.csv\"\n",
    "df.to_csv(cleaned_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b3bf462",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_file = r\"C:\\Users\\Acer\\Documents\\DataSprint\\data\\cleaned.csv\"\n",
    "df = pd.read_csv(cleaned_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adfd856",
   "metadata": {},
   "source": [
    "cleaning the gender and country column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6def7813",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(cleaned_file)\n",
    "\n",
    "df ['gender'].isnull().sum()\n",
    "\n",
    "#dropping the null values\n",
    "df = df.dropna(subset=['gender'])\n",
    "\n",
    "df['gender'] = df['gender'].astype(str).str.lower().str.strip()\n",
    "\n",
    "gender_map = {\n",
    "    'f' : 'Female',\n",
    "    'female': 'Female',\n",
    "\n",
    "    'm' : 'Male',\n",
    "    'male': 'Male',\n",
    "\n",
    "    'other' : 'Other'\n",
    "}\n",
    "\n",
    "df['gender'] = df['gender'].map(gender_map)\n",
    "\n",
    "\n",
    "df['country'].isnull().sum()\n",
    "\n",
    "df['country'] = (df['country'].astype(str).str.lower().str.strip().str.replace('.', '', regex = False))\n",
    "\n",
    "country_map = {\n",
    "    'uk' : 'United Kingdom',\n",
    "    'united kingdom' : 'United Kingdom',\n",
    "    'usa' : 'United States',\n",
    "    'ind' : 'India',\n",
    "}\n",
    "\n",
    "df['country'] = df['country'].map(country_map).fillna(df['country'])\n",
    "df['country'] = df['country'].str.title()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d67f155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(cleaned_file)\n",
    "cleaned_file = r\"C:\\Users\\Acer\\Documents\\DataSprint\\data\\cleaned.csv\"\n",
    "df.to_csv(cleaned_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9c8131",
   "metadata": {},
   "source": [
    "subscription_type cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a42db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Premium', 'Student', 'Family', 'Free'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subscription_type'].unique()\n",
    "\n",
    "df['subscription_type'] = (df['subscription_type'].astype(str).str.lower().str.strip())\n",
    "\n",
    "subscription_map = {\n",
    "    'studnt' : 'student',\n",
    "    'fam' : 'family',\n",
    "    'premum' : 'premium',\n",
    "}\n",
    "\n",
    "df['subscription_type'] = df['subscription_type'].map(subscription_map).fillna(df['subscription_type'])\n",
    "df['subscription_type'] = df['subscription_type'].str.title()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0615dec4",
   "metadata": {},
   "source": [
    "Inspect and cleaning satisfaction_score & skip rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf077c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['satisfaction_score'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8400ad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_skip_rate(x):\n",
    "    x = str(x).strip().lower()\n",
    "\n",
    "    if \"%\" in x:\n",
    "        x = x.replace(\"%\", \"\")\n",
    "        return pd.to_numeric(x, errors=\"coerce\") / 100\n",
    "\n",
    "    num = pd.to_numeric(x, errors=\"coerce\")\n",
    "    if pd.notna(num):\n",
    "        return num\n",
    "\n",
    "    words = {\n",
    "        \"zero\": 0,\n",
    "        \"one\": 1,\n",
    "        \"two\": 2,\n",
    "        \"three\": 3,\n",
    "        \"four\": 4,\n",
    "        \"five\": 5,\n",
    "        \"six\": 6,\n",
    "        \"seven\": 7,\n",
    "        \"eight\": 8,\n",
    "        \"nine\": 9,\n",
    "        \"ten\": 10\n",
    "    }\n",
    "\n",
    "    if x in words:\n",
    "        return words[x]\n",
    "\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "df[\"skip_rate\"] = df[\"skip_rate\"].apply(clean_skip_rate)\n",
    "\n",
    "df[\"skip_rate\"] = df[\"skip_rate\"].apply(\n",
    "    lambda x: x/100 if pd.notna(x) and x > 1 else x\n",
    ")\n",
    "\n",
    "df[[\"skip_rate\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a735e8",
   "metadata": {},
   "source": [
    "mapping churned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2117ed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['churned'].unique()\n",
    "\n",
    "df['churned'] = (df['churned'].astype(str).str.capitalize().str.strip())\n",
    "\n",
    "churned_map ={\n",
    "    '1' : 'Yes',\n",
    "    '0' : 'No',\n",
    "}\n",
    "\n",
    "df['churned'] = df['churned'].map(churned_map).fillna(df['churned'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d5527c",
   "metadata": {},
   "source": [
    "cleaning monthly_fee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fd92a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_monthly_fee(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    x = str(x).strip().lower()\n",
    "    x = x.replace(\"usd\", \"\").replace(\"$\", \"\").strip()\n",
    "\n",
    "    num = pd.to_numeric(x, errors = 'coerce')\n",
    "    if pd.notna(num):\n",
    "        return num\n",
    "    if x in [\"free\", \"none\", \"no fee\"]:\n",
    "        return 0.0\n",
    "    return np.nan \n",
    "df['monthly_fee_clean'] = df['monthly_fee'].apply(clean_monthly_fee)\n",
    "\n",
    "df[['monthly_fee', 'monthly_fee_clean']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5513198a",
   "metadata": {},
   "source": [
    "cleaning join_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07c1f6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_7436\\2326303815.py:7: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(x, dayfirst=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "join_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "date_clean",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        }
       ],
       "ref": "cc3ae420-4404-4d43-a7fa-1da611946c3d",
       "rows": [
        [
         "0",
         "03/21/2024",
         "2024-03-21 00:00:00"
        ],
        [
         "1",
         "08/10/2023",
         "2023-10-08 00:00:00"
        ],
        [
         "2",
         "04/05/2022",
         "2022-05-04 00:00:00"
        ],
        [
         "3",
         "12/16/2023",
         "2023-12-16 00:00:00"
        ],
        [
         "4",
         "03/28/2022",
         "2022-03-28 00:00:00"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>join_date</th>\n",
       "      <th>date_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03/21/2024</td>\n",
       "      <td>2024-03-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08/10/2023</td>\n",
       "      <td>2023-10-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04/05/2022</td>\n",
       "      <td>2022-05-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/16/2023</td>\n",
       "      <td>2023-12-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03/28/2022</td>\n",
       "      <td>2022-03-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    join_date date_clean\n",
       "0  03/21/2024 2024-03-21\n",
       "1  08/10/2023 2023-10-08\n",
       "2  04/05/2022 2022-05-04\n",
       "3  12/16/2023 2023-12-16\n",
       "4  03/28/2022 2022-03-28"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_date(x):\n",
    "    if pd.isna(x):\n",
    "        return pd.NaT\n",
    "    x = str(x).strip()\n",
    "\n",
    "    try:\n",
    "        return pd.to_datetime(x, dayfirst=True)\n",
    "    except:\n",
    "        try:\n",
    "            return pd.to_datetime(x, dayfirst=False)\n",
    "        except:\n",
    "            return pd.NaT\n",
    "\n",
    "df['date_clean'] = df['join_date'].apply(clean_date)\n",
    "df[['join_date', 'date_clean']].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
